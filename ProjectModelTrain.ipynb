{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rijann12/Python/blob/main/ProjectModelTrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Prjzt277vWkM"
      },
      "source": [
        "#Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7oXxCULvLxi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6HtHc5OvbJM"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmz1EqAavhjd"
      },
      "source": [
        "## Training Image Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYPmkHQIvezK",
        "outputId": "e4a21284-8dd8-4644-8f0c-41c4c5f35eb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 15143 files belonging to 8 classes.\n"
          ]
        }
      ],
      "source": [
        "training_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/DataTrain/train',\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=64,\n",
        "    image_size=(128, 128),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False,\n",
        "    pad_to_aspect_ratio=False,\n",
        "    data_format=None,\n",
        "    verbose=True,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gXBUhc4Szv2"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoGxaYpiDG2V"
      },
      "outputs": [],
      "source": [
        "training_set\n",
        "training_set = training_set.prefetch(buffer_size=tf.data.AUTOTUNE) # prefetch() helps in pieplining.So, one process runs in parallel(overlapping) with another process (like CPU loading and preparing next batch).\n",
        "# while GPU is training on batch n,CPU is already preparing batch n+1 in background.Basically for faster training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCqgDsjKDLCl"
      },
      "outputs": [],
      "source": [
        "for x,y in training_set:\n",
        "  print(x,x.shape)\n",
        "  print(y,y.shape)\n",
        "  break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17BtCQ9LzEGR"
      },
      "source": [
        "## Validation Image Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiRh02IUzIuq"
      },
      "outputs": [],
      "source": [
        "validation_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/DataTrain/valid',\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=64,\n",
        "    image_size=(128, 128),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False,\n",
        "    pad_to_aspect_ratio=False,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KsMO6aKFcNf"
      },
      "outputs": [],
      "source": [
        "validation_set\n",
        "validation_set = validation_set.prefetch(buffer_size=tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1Uwvno-D37a"
      },
      "source": [
        "## To avoid Overshooting\n",
        "1. Choose small learning rate default 0.001 we are taking 0.0001\n",
        "2. There may be chance of Underfitting, so incresase number of neuron\n",
        "3. Add more Convolutional layer to extract more feature from images there may  be possibility that the model uanle to captutre relevant feature or model is confusing due to lack of feature so feed with more feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8_chZfm1Why"
      },
      "source": [
        "# Building Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0FIpU8R1ZVr"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Flatten,Dropout\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2O-7uJEd1tgx"
      },
      "outputs": [],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahH7Nnv51xZ7"
      },
      "outputs": [],
      "source": [
        "#Building Convolutional Layer\n",
        "model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu',input_shape=(128,128,3)))\n",
        "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=2,strides=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TB1o_LL328uk"
      },
      "outputs": [],
      "source": [
        "model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=2,strides=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jO2JqHE3BXU"
      },
      "outputs": [],
      "source": [
        "model.add(Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(Conv2D(filters=128, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=2,strides=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xYNk41ya3Ix4"
      },
      "outputs": [],
      "source": [
        "model.add(Conv2D(filters=256, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(Conv2D(filters=256, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=2,strides=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiXswo6RIt6c"
      },
      "outputs": [],
      "source": [
        "model.add(Conv2D(filters=512, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(Conv2D(filters=512, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=2,strides=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdjCsBiNJLfw"
      },
      "outputs": [],
      "source": [
        "model.add(Dropout(0.25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGesuOch9o1i"
      },
      "outputs": [],
      "source": [
        "model.add(Flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9Ox9yNK3SgW"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(units=1500, activation='relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNUMSTTfJUMH"
      },
      "outputs": [],
      "source": [
        "model.add(Dropout(0.4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Matu97TI84K8"
      },
      "outputs": [],
      "source": [
        "# Output layer\n",
        "model.add(Dense(units=22, activation='softmax'))#units are the no of class present in the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dttFyr59Ifz"
      },
      "source": [
        "#Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAG_MC7H9HK7"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.0001), loss='categorical_crossentropy',metrics=['accuracy'] )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtO-Sydr98aP"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gltEU-Di_AhY"
      },
      "source": [
        "#Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUp6vegSIaGe"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "training_history = model.fit(\n",
        "    training_set,\n",
        "    validation_data=validation_set,\n",
        "    epochs=14,\n",
        "    callbacks=[early_stop]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7vPuojdw_C95"
      },
      "outputs": [],
      "source": [
        "#training_history = model.fit(x=training_set, validation_data=validation_set, epochs=9\n",
        "                             )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ahjJlRmMxX3"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBgYwBnNko1w"
      },
      "outputs": [],
      "source": [
        "# Model Evaluation on Training Set\n",
        "train_loss, train_acc = model.evaluate(training_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUbkBDN_NFJD"
      },
      "outputs": [],
      "source": [
        "print(\"Train loss:\",train_loss, \"Train Accuracy:\",train_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y19gZe4YNIc3"
      },
      "outputs": [],
      "source": [
        "# Model validation Set\n",
        "val_loss, val_acc = model.evaluate(validation_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4G-52VcK2g4"
      },
      "outputs": [],
      "source": [
        "print(\"Validation loss:\", val_loss, \"Validation accuracy:\", val_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AY36aHajNYky"
      },
      "source": [
        "# Saving model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_WcX4-HJh9E"
      },
      "outputs": [],
      "source": [
        "model.save(\"trained_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKewHvI5Nash"
      },
      "outputs": [],
      "source": [
        "# To save this file we have used 'keras' format as it compresses the file size whereas '.h5' format takes up more file size\n",
        "model.save(\"trained_model.keras\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-3S818bOI7n"
      },
      "outputs": [],
      "source": [
        "training_history.history\n",
        "# validation accuracy tara validation garesi garne\n",
        "#training_history.history(val_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFxKWUGgOgyP"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6bbM4yWOYAL"
      },
      "outputs": [],
      "source": [
        "# Recording the histroy in json\n",
        "# We have saved this training history in 'json' for future use of the data or perform data visualization as we can just read this history\n",
        "# Also for the future use of the this model as we cannot run the model again and again if we need it for future\n",
        "import json\n",
        "with open(\"training_hist.json\",\"w\") as f:\n",
        "  json.dump(training_history.history,f);\n",
        "\n",
        "print(\"Model & training history saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gy-bYBTLL31k"
      },
      "outputs": [],
      "source": [
        "# model.evaluate() computes loss and accuracy metrics on given dataset\n",
        "# It checks for overfittting, if training accuracy higher than validation accuracy, model might be overfitting.\n",
        "train_loss, train_acc = model.evaluate(training_set)\n",
        "print(f\"Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\")\n",
        "\n",
        "val_loss, val_acc = model.evaluate(validation_set)\n",
        "print(f\"Valid Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unhR9me3PAEF"
      },
      "source": [
        "# Accuracy Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GY_Xnj26PC_I"
      },
      "outputs": [],
      "source": [
        "epochs = range(1, len(training_history.history['accuracy']) + 1)\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(epochs, training_history.history['accuracy'], 'r', label='Train Acc')\n",
        "plt.plot(epochs, training_history.history['val_accuracy'], 'b', label='Val Acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training & Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8-pDNvXPLYh"
      },
      "outputs": [],
      "source": [
        "# epochs = { i for in range(1,1)}\n",
        "# plt.plot(epochs, training_history.history ['accuracy'], color= 'red', label='Training Accuracy')\n",
        "# plt.plot(epochs, training_history.history ['val_accuracy'], color= 'blue', label='Vlaidation Accuracy')\n",
        "# plt.xlabel(\"No. of epochs\")\n",
        "# plt.ylabel(\"Accuracy Result\")\n",
        "# plt.title(\"Visualization Accuracy Result\")\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOFKJpQZ_yIq"
      },
      "source": [
        "# Some other matrices for model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKOgl5oZ_xEu"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2X3tw9tFYXK"
      },
      "outputs": [],
      "source": [
        "  class_name = validation_set.class_names\n",
        "  class_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WweBkMPAcjf"
      },
      "outputs": [],
      "source": [
        "test_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/DataTrain/valid',\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=(128, 128),\n",
        "    shuffle=False,# Setting shuffle as False for the testing passes the folders from validation folder sequentially from starting to bottom\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False,\n",
        "    pad_to_aspect_ratio=False,\n",
        "    verbose=True,\n",
        ")\n",
        "test_set = test_set.prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiKx4ucwBqbs"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(test_set)\n",
        "y_pred, y_pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxkvoBEzB4Fn"
      },
      "outputs": [],
      "source": [
        "predicted_categories = tf.argmax(y_pred,axis=1) # this goes to inside y_pred and extract the maximum value and return the index of that max value and axis=1 means it return the index in column wise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNLUwEPKCkh8"
      },
      "outputs": [],
      "source": [
        "predicted_categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXdK70aqCpyY"
      },
      "outputs": [],
      "source": [
        "# true_categories = tf.concat( [y for x,y in test_set], axis=0)\n",
        "# true_categories\n",
        "true_categories = tf.concat([labels for _, labels in test_set], axis=0)\n",
        "true_categories = tf.argmax(true_categories, axis=1)\n",
        "true_categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyNcpYIxESH3"
      },
      "outputs": [],
      "source": [
        "# Y_true=predicted_categories = tf.argmax(y_pred,axis=1)\n",
        "# Y_true\n",
        "Y_true = true_categories\n",
        "Y_pred = predicted_categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a13Xi4uKEWGv"
      },
      "outputs": [],
      "source": [
        "# Calcualate Precision recall\n",
        "# Precision measures the precentage made by the model that are correct.\n",
        "# Recall measures the percenatage of the relevant data points that were correctly identified by the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jb8wQxbAEfJD"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSBYPcfqFjxV"
      },
      "outputs": [],
      "source": [
        "#print(classification_report(Y_true, predicted_categories target_names=class_name))\n",
        "print(classification_report(Y_true.numpy(), Y_pred.numpy(), target_names=class_name))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oG11vP-LGHF2"
      },
      "outputs": [],
      "source": [
        "# F-1 score calculation, perfect model have F-1 score of 1.\n",
        "# cm = confusion_matrix(Y_true, predicted_categories)\n",
        "cm = confusion_matrix(Y_true.numpy(), Y_pred.numpy())\n",
        "cm.shape()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12NM5qMJHDNb"
      },
      "source": [
        "# Visualization of Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nO5SoLy9Gxj9"
      },
      "outputs": [],
      "source": [
        "#sns.heatmap(cm)\n",
        "plt.figure(figsize=(40, 40))\n",
        "sns.heatmap(cm, annot=True, annot_kws={'size':10})\n",
        "plt.xlabel(\"Predicted Class\", fontsize=20)\n",
        "plt.ylabel(\"Actual Class\", fontsize=20)\n",
        "plt.title(\"Plant Disease Confusion Matrix\", fontsize=20)\n",
        "plt.show()\n",
        "# the result is saying it is confusion matix and the diagonal element is saying that it belongs to that class and actually it belings to that class\n",
        "# we can tune this model by adjusting filters, improving no. of nuerons, adjusting loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdAPMJDEIq7n"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "11NnageCGONpmsTd56PQfYkF2TLq0nZlm",
      "authorship_tag": "ABX9TyM6dn8oV4Ghsh0HEGhCunHt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}